{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nasibehmohammadi/Thesis/blob/main/gan_gru_d4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Da4u1CWRSVPL",
        "outputId": "f374954a-f427-4e9e-d14d-8407181d5821"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔹 نام ستون‌های دیتاست: Index(['A', 'B', 'C'], dtype='object')\n",
            "🔹 ستون‌های پیشنهادی برای target: ['A']\n",
            "🔹 مقدارهای یکتا در target: (array([0, 1]), array([ 1897, 69709]))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py:82: UserWarning: The model does not have any trainable weights.\n",
            "  warnings.warn(\"The model does not have any trainable weights.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Discriminator Loss: 0.6915, Generator Loss: 0.6932\n",
            "Epoch 100: Discriminator Loss: 0.6922, Generator Loss: 0.6912\n",
            "Epoch 200: Discriminator Loss: 0.6954, Generator Loss: 0.6833\n",
            "Epoch 300: Discriminator Loss: 0.6977, Generator Loss: 0.6782\n",
            "Epoch 400: Discriminator Loss: 0.6990, Generator Loss: 0.6755\n",
            "Epoch 500: Discriminator Loss: 0.6997, Generator Loss: 0.6739\n",
            "Epoch 600: Discriminator Loss: 0.7002, Generator Loss: 0.6727\n",
            "Epoch 700: Discriminator Loss: 0.7006, Generator Loss: 0.6718\n",
            "Epoch 800: Discriminator Loss: 0.7010, Generator Loss: 0.6711\n",
            "Epoch 900: Discriminator Loss: 0.7013, Generator Loss: 0.6706\n",
            "✅ Balanced dataset saved as /content/UCIP_balanced_WithGRU.csv\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "🔹 توزیع کلاس‌ها در پیش‌بینی مدل: (array([1]), array([14322]))\n",
            "✅ Accuracy: 0.9737\n",
            "✅ F1-Score: 0.9867\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import GRU, Dense, Dropout, Reshape, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "file_path = \"/content/UCIP.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(\"🔹 نام ستون‌های دیتاست:\", df.columns)\n",
        "\n",
        "potential_targets = [col for col in df.columns if df[col].nunique() <= 10]\n",
        "print(\"🔹 ستون‌های پیشنهادی برای target:\", potential_targets)\n",
        "\n",
        "target_column = \"A\"\n",
        "if target_column not in df.columns or df[target_column].nunique() > 10:\n",
        "    print(\"❌ ستون 'A' اشتباه است! در حال جایگزینی...\")\n",
        "    target_column = potential_targets[0]\n",
        "    print(f\"✅ ستون هدف جدید: {target_column}\")\n",
        "\n",
        "features = df.drop(columns=[target_column]).values\n",
        "target = df[target_column].values\n",
        "\n",
        "print(\"🔹 مقدارهای یکتا در target:\", np.unique(target, return_counts=True))\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "features_scaled = scaler.fit_transform(features)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features_scaled, target, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "assert len(np.unique(y_train)) > 1, \"❌ خطا: فقط یک کلاس در y_train وجود دارد!\"\n",
        "\n",
        "def build_generator():\n",
        "    model = Sequential([\n",
        "        Input(shape=(1, X_train.shape[2])),\n",
        "        GRU(128, return_sequences=True),\n",
        "        Dropout(0.2),\n",
        "        GRU(64, return_sequences=True),\n",
        "        Dropout(0.2),\n",
        "        GRU(32, return_sequences=False),\n",
        "        Dense(X_train.shape[2]),\n",
        "        Reshape((1, X_train.shape[2]))\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def build_discriminator():\n",
        "    model = Sequential([\n",
        "        Input(shape=(1, X_train.shape[2])),\n",
        "        GRU(128, return_sequences=True),\n",
        "        Dropout(0.3),\n",
        "        GRU(64, return_sequences=False),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def build_gan(generator, discriminator):\n",
        "    discriminator.trainable = False\n",
        "    model = Sequential([generator, discriminator])\n",
        "    return model\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer=Adam(0.0002, 0.5), metrics=[\"accuracy\"])\n",
        "\n",
        "generator = build_generator()\n",
        "gan = build_gan(generator, discriminator)\n",
        "gan.compile(loss=\"binary_crossentropy\", optimizer=Adam(0.0002, 0.5))\n",
        "\n",
        "epochs = 1000\n",
        "batch_size = 128\n",
        "half_batch = batch_size // 2\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    noise = np.random.normal(0, 1, (half_batch, 1, X_train.shape[2]))\n",
        "    generated_data = generator.predict(noise, verbose=0)\n",
        "\n",
        "    idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
        "    real_data = X_train[idx]\n",
        "\n",
        "    real_labels = np.random.uniform(0.8, 1.0, (half_batch, 1))\n",
        "    fake_labels = np.random.uniform(0.0, 0.2, (half_batch, 1))\n",
        "\n",
        "    X_combined = np.concatenate((real_data, generated_data))\n",
        "    y_combined = np.concatenate((real_labels, fake_labels))\n",
        "\n",
        "    if epoch % 2 == 0:\n",
        "        d_loss = discriminator.train_on_batch(X_combined, y_combined)\n",
        "\n",
        "    noise = np.random.normal(0, 1, (batch_size, 1, X_train.shape[2]))\n",
        "    y_mislabeled = np.ones((batch_size, 1))\n",
        "\n",
        "    g_loss = gan.train_on_batch(noise, y_mislabeled)\n",
        "\n",
        "    d_loss = float(d_loss[0]) if isinstance(d_loss, list) else float(d_loss)\n",
        "    g_loss = float(g_loss[0]) if isinstance(g_loss, list) else float(g_loss)\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}: Discriminator Loss: {d_loss:.4f}, Generator Loss: {g_loss:.4f}\")\n",
        "\n",
        "minority_class = 0 if np.bincount(y_train)[0] < np.bincount(y_train)[1] else 1\n",
        "num_samples_to_generate = abs(np.bincount(y_train)[0] - np.bincount(y_train)[1])\n",
        "\n",
        "noise = np.random.normal(0, 1, (num_samples_to_generate, 1, X_train.shape[2]))\n",
        "generated_samples = generator.predict(noise, verbose=0)\n",
        "\n",
        "synthetic_labels = np.full((num_samples_to_generate,), minority_class)\n",
        "\n",
        "X_balanced = np.concatenate((X_train.squeeze(), generated_samples.squeeze()))\n",
        "y_balanced = np.concatenate((y_train, synthetic_labels))\n",
        "\n",
        "df_balanced = pd.DataFrame(X_balanced)\n",
        "df_balanced.insert(0, target_column, y_balanced)  # قرار دادن ستون هدف در ستون اول\n",
        "\n",
        "balanced_file_path = \"/content/UCIP_balanced_WithGRU.csv\"\n",
        "df_balanced.to_csv(balanced_file_path, index=False)\n",
        "print(f\"✅ Balanced dataset saved as {balanced_file_path}\")\n",
        "\n",
        "y_pred_probs = discriminator.predict(X_test, batch_size=512, verbose=1)\n",
        "y_pred = (y_pred_probs > 0.5).astype(int).flatten()\n",
        "\n",
        "print(\"🔹 توزیع کلاس‌ها در پیش‌بینی مدل:\", np.unique(y_pred, return_counts=True))\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"✅ Accuracy: {accuracy:.4f}\")\n",
        "print(f\"✅ F1-Score: {f1:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "name": "gan_gru_d4.ipynb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}